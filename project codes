### Project Codes

**Prerequisites**
- must have a Twitter Developer Account
token <- rtweet::create_token(
  app = "Data Review",
  consumer_key <- "[consumerkey]",
  consumer_secret <- "[consumersecret]",
  access_token <- "[accesstoken]",
  access_secret <- "[access_secret]"
  
## Check token
rtweet::get_token()
  
library(rtweet)
library(igraph)
library(tidyverse)
library(ggraph)
library(data.table)
install.packages("widgetframe")
library(widgetframe)
install.packages("twitteR")
library(twitteR)
library("lubridate")
library("ggplot2")
install.packages(c("tm", "wordcloud"))
library("tm")
library("wordcloud")
library(syuzhet)

# EXTRACT DATA

STOPVOTERSUPPRESSION <- rtweet::search_tweets(q = "#STOPVOTERSUPPRESSION", n = 500, lang = "en")

PROTECTTHEVOTE <- rtweet::search_tweets(q = "#PROTECTTHEVOTE", n = 100, lang = "en")

STANDWITHPARK <- rtweet::search_tweets(q = "#STANDWITHPARK", n = 500, lang = "en")

KILLTHEBILL <- rtweet::search_tweets(q = "#KILLTHEBILL", n = 100, lang = "en")

PROTECTBLACKWOMEN <- rtweet::search_tweets(q = "#PROTECTBLACKWOMEN", n = 100, lang = "en")


install.packages("rtweet")
library("rtweet")

bk_tweets <- get_timeline("GovKemp", n = 1000)
pc_tweets <- get_timeline("Cannonfor58", n = 1000)
```


#list of variables included
states=row.names(bk_tweets)
names(bk_tweets)

# VISUALS

install.packages(c("tm", "wordcloud"))
library("tm")
library("wordcloud")
library(tidyverse)

##WORD CLOUD
tweet_text <- STANDWITHPARK$text
#Removing numbers, punctations, links and alphanumeric content
tweet_text<- gsub('[[:digit:]]+',"", tweet_text)
tweet_text<- gsub('[[:punct:]]+',"", tweet_text)
tweet_text<- gsub('http[[:alnum:]]*', "", tweet_text)
tweet_text<- gsub('([[:alpha:]])\1+', "", tweet_text)
#creating a text corpus
docs <- Corpus(VectorSource(tweet_text))
# coverting the encoding to UTF-8 to handle funny characters
docs <- tm_map(docs, function(x) iconv(enc2utf8(x), sub = "byte"))
# Converting the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Removing english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Removing stopwords specified by us as a character vector
docs <- tm_map(docs, removeWords, c("amp"))
# creating term document matrix
tdm <- TermDocumentMatrix(docs)
# defining tdm as matrix
m <- as.matrix(tdm)
# getting word counts in decreasing order
word_freqs = sort(rowSums(m), decreasing=TRUE)
# creating a data frame with words and their frequencies
park_wf <- data.frame(word=names(word_freqs), freq=word_freqs)
# plotting wordcloud
set.seed(1234)
wordcloud(words = park_wf$word, freq = park_wf$freq,
          min.freq = 1,scale=c(1.8,.5),
          max.words=200, random.order=FALSE, rot.per=0.15,
          colors=brewer.pal(8, "RdBu"))
* RcolorBrewer used to change color theme


##WORD CLOUD

tweet_text <- STOPVOTERSUPPRESSION$text
#Removing numbers, punctations, links and alphanumeric content
tweet_text<- gsub('[[:digit:]]+',"", tweet_text)
tweet_text<- gsub('[[:punct:]]+',"", tweet_text)
tweet_text<- gsub('http[[:alnum:]]*', "", tweet_text)
tweet_text<- gsub('([[:alpha:]])\1+', "", tweet_text)
#creating a text corpus
docs <- Corpus(VectorSource(tweet_text))
# coverting the encoding to UTF-8 to handle funny characters
docs <- tm_map(docs, function(x) iconv(enc2utf8(x), sub = "byte"))
# Converting the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Removing english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Removing stopwords specified by us as a character vector
docs <- tm_map(docs, removeWords, c("amp"))
# creating term document matrix
tdm <- TermDocumentMatrix(docs)
# defining tdm as matrix
m <- as.matrix(tdm)
# getting word counts in decreasing order
word_freqs = sort(rowSums(m), decreasing=TRUE)
# creating a data frame with words and their frequencies
suppression_wf <- data.frame(word=names(word_freqs), freq=word_freqs)
# plotting wordcloud
set.seed(1234)
wordcloud(words = suppression_wf$word, freq = park_wf$freq,
          min.freq = 1,scale=c(1.8,.5),
          max.words=200, random.order=FALSE, rot.per=0.15,
          colors=brewer.pal(8, "RdGy"))


##Frequency of Tweets

install.packages("lubridate")
library("lubridate")
library("ggplot2")

ggplot(data = bk_tweets,
       aes(month(created_at, label=TRUE, abbr=TRUE),
           group=factor(year(created_at)), color=factor(year(created_at))))+
  geom_line(stat="count") +
  geom_point(stat="count") +
  labs(x="Month", colour="Year") +
  ggtitle("Brian Kemp's Tweets") +
  xlab("Month") + ylab("Number of tweets") +
  scale_color_brewer(palette="Set1")


ggplot(data = pc_tweets,
       aes(month(created_at, label=TRUE, abbr=TRUE),
           group=factor(year(created_at)), color=factor(year(created_at))))+
  geom_line(stat="count") +
  geom_point(stat="count") +
  labs(x="Month", colour="Year") +
  ggtitle("Park Cannon's Tweets") +
  xlab("Month") + ylab("Number of tweets") +
  scale_color_brewer(palette="Set1")


##Retweets

# BRIAN KEMP RETWEETS

ggplot(bk_tweets, aes(x = created_at, y = retweet_count)) +
  geom_point(colour = "white", alpha = 0.5, size = 2) +
  geom_smooth(se = FALSE, colour = "red", alpha = 0.5) +
  theme_minimal()  +
  labs(x = "Date", y = " Number of Retweets", 
       title = "Retweeted tweets from '@GovKemp'") 

# PARK CANNON RETWEETS

ggplot(pc_tweets, aes(x = created_at, y = retweet_count)) +
  geom_point(colour = "white", alpha = 0.5, size = 2) +
  geom_smooth(se = FALSE, colour = "blue", alpha = 0.5) +
  ylim(1000, 5000) +
  theme_minimal()  +
  labs(x = "Date", y = " Number of Retweets", 
       title = "Retweeted tweets from '@Cannonfor58'") 
  
```
